{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuralnet import Neuralnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os, gzip\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradient\n",
    "from constants import *\n",
    "from train import *\n",
    "from gradient import *\n",
    "import util\n",
    "import argparse\n",
    "import neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    # Read the required config\n",
    "    # Create different config files for different experiments\n",
    "    configFile = None #Will contain the name of the config file to be loaded\n",
    "    if (args.experiment == 'test_gradients'):  #3b\n",
    "        configFile = 'config_3b.yaml' # Create a config file for 3b and change None to the config file name\n",
    "    elif(args.experiment=='test_momentum'):  #3c\n",
    "        configFile = \"config_3c.yaml\" # Create a config file for 3c and change None to the config file name\n",
    "    elif (args.experiment == 'test_regularization'): #3d\n",
    "        configFile = None # Create a config file for 3d and change None to the config file name\n",
    "    elif (args.experiment == 'test_activation'): #3e\n",
    "        configFile = None # Create a config file for 3e and change None to the config file name\n",
    "    elif (args.experiment == 'test_hidden_units'):  #3f-i\n",
    "        configFile = None # Create a config file for 3f-i and change None to the config file name\n",
    "    elif (args.experiment == 'test_hidden_layers'):  #3f-ii\n",
    "        configFile = None # Create a config file for 3f-ii and change None to the config file name\n",
    "    elif (args.experiment == 'test_100_classes'):  #3g\n",
    "        configFile = None # Create a config file for 3g and change None to the config file name. Please make the necessaty changes to load_data()\n",
    "        # in util.py first before running this experiment\n",
    "\n",
    "    # Load the data\n",
    "    x_train, y_train, x_valid, y_valid, x_test, y_test = util.load_data(path='')  # Set datasetDir in constants.py\n",
    "\n",
    "    # Load the configuration from the corresponding yaml file. Specify the file path and name\n",
    "    config = util.load_config('configs/' + configFile) # Set configYamlPath, configFile  in constants.py\n",
    "\n",
    "    if(args.experiment == 'test_gradients'):\n",
    "        subsetSize = 5  #Feel free to change this\n",
    "        sample_idx = np.random.randint(0,len(x_train),subsetSize)\n",
    "        x_train_sample, y_train_sample = x_train[sample_idx], y_train[sample_idx]\n",
    "        model = Neuralnetwork(config)\n",
    "        results  = check_grad(model, x_train_sample, y_train_sample)\n",
    "      \n",
    "        return results\n",
    "\n",
    "    # Create a Neural Network object which will be our model\n",
    "    model = neuralnet.Neuralnetwork(config)\n",
    "\n",
    "    # train the model. Use train.py's train method for this\n",
    "    model = modeltrain(model, x_train, y_train, x_valid, y_valid, config)\n",
    "\n",
    "    # test the model. Use train.py's modelTest method for this\n",
    "    test_acc, test_loss =  modelTest(model, x_test, y_test)\n",
    "\n",
    "    # Print test accuracy and test loss\n",
    "    print('Test Accuracy:', test_acc, ' Test Loss:', test_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--experiment', type=str, default='test_gradients', help='Specify the experiment that you want to run')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "#args = parser.parse_args()# This specifies the number of layers and number of hidden neurons in each layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight type                numerical gradient           true gradient         absolute difference\n",
      "('output layer bias weight', -7.473294338029568e-05, 5.1535591235313295e-06, 7.9886502503827e-05)\n",
      "\n",
      "\n",
      "('hiden layer bias weight', -5.879822996135431e-07, 5.1535591235313295e-06, 5.741541423144872e-06)\n",
      "\n",
      "\n",
      "('hidden to output weight #1', -2.065973648862851e-05, 9.803444316535384e-05, 0.00011869417965398235)\n",
      "\n",
      "\n",
      "('hidden to output weight #2', -1.4476268714016528e-05, 4.889707240854833e-05, 6.337334112256485e-05)\n",
      "\n",
      "\n",
      "('input to hidden weight #1', -4.136323141423759e-07, 4.889707240854833e-05, 4.9310704722690706e-05)\n",
      "\n",
      "\n",
      "('input to hidden weight #2', -6.562391244635535e-07, 9.803444316535384e-05, 9.86906822898174e-05)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('weight type               ', 'numerical gradient          ', 'true gradient        ', 'absolute difference')\n",
    "for i in range(len(results)):\n",
    "    print(results[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grad(model, x_train, y_train):\n",
    "\n",
    "    \"\"\"\n",
    "    TODO\n",
    "        Checks if gradients computed numerically are within O(epsilon**2)\n",
    "\n",
    "        args:\n",
    "            model\n",
    "            x_train: Small subset of the original train dataset\n",
    "            y_train: Corresponding target labels of x_train\n",
    "\n",
    "        Prints gradient difference of values calculated via numerical approximation and backprop implementation\n",
    "    \"\"\"\n",
    "    epsilon = 10**(-2)\n",
    "    results = []\n",
    "    #1 output layer bias weight\n",
    "    output_layer = model.layers[1]\n",
    "    out_bias_w = output_layer.w[0][1]\n",
    "    model(x_train, y_train)\n",
    "    deltas = model.backward(False)\n",
    "    delta = deltas[0][1]\n",
    "    \n",
    "    output_layer.w[0][1] = out_bias_w + epsilon\n",
    "    loss_plus, acc = model(x_train, y_train)\n",
    "    \n",
    "    output_layer.w[0][1] = out_bias_w - epsilon\n",
    "    loss_minus, acc = model(x_train, y_train)\n",
    "    output_layer.w[0][1] = out_bias_w\n",
    "    \n",
    "    num_delta = (loss_plus - loss_minus) / 2*epsilon\n",
    "\n",
    "    abs_diff = abs(delta - num_delta)\n",
    "    \n",
    "    results.append(('output layer bias weight',num_delta, delta, abs_diff))\n",
    "    \n",
    "    #2 hidden bias weight\n",
    "    hidden_layer = model.layers[0]\n",
    "    hidden_bias_w = hidden_layer.w[0][1]\n",
    "    model(x_train, y_train)\n",
    "    deltas = model.backward(False)\n",
    "    delta2 = deltas[0][1]\n",
    "    \n",
    "    hidden_layer.w[0][1] = hidden_bias_w + epsilon\n",
    "    loss_plus, acc = model(x_train, y_train)\n",
    "    \n",
    "    hidden_layer.w[0][1] = hidden_bias_w - epsilon\n",
    "    loss_minus, acc = model(x_train, y_train)\n",
    "    hidden_layer.w[0][1] = hidden_bias_w\n",
    "    \n",
    "    num_delta2 = (loss_plus - loss_minus) / 2*epsilon\n",
    "    abs_diff2 = abs(delta2 - num_delta2)\n",
    "    \n",
    "    results.append(('hiden layer bias weight',num_delta2, delta2, abs_diff2))\n",
    "    \n",
    "    \n",
    "    #3 hidden to output weight #1\n",
    "    output_layer = model.layers[1]\n",
    "    w3 = output_layer.w[4][0]\n",
    "    \n",
    "    model(x_train, y_train)\n",
    "    deltas = model.backward(False)\n",
    "    delta3 = deltas[4][0]\n",
    "    \n",
    "    output_layer.w[4][0] = w3 + epsilon\n",
    "    loss_plus, acc = model(x_train, y_train)\n",
    "    \n",
    "    output_layer.w[4][0] = w3 - epsilon\n",
    "    loss_minus, acc = model(x_train, y_train)\n",
    "    output_layer.w[4][0] = w3 \n",
    "\n",
    "    num_delta3 = (loss_plus - loss_minus) / 2*epsilon\n",
    "    abs_diff3 = abs(delta3 - num_delta3)\n",
    "    \n",
    "    results.append(('hidden to output weight #1', num_delta3, delta3, abs_diff3))\n",
    "    \n",
    "    \n",
    "    #4 hidden to output weight #2\n",
    "    output_layer = model.layers[1]\n",
    "    w1 = output_layer.w[2][0]\n",
    "    \n",
    "    model(x_train, y_train)\n",
    "    deltas = model.backward(False)\n",
    "    delta4 = deltas[2][0]\n",
    "    \n",
    "    output_layer.w[2][0] = w1 + epsilon\n",
    "    loss_plus, acc = model(x_train, y_train)\n",
    "    \n",
    "    output_layer.w[2][0] = w1 - epsilon\n",
    "    loss_minus, acc = model(x_train, y_train)\n",
    "    output_layer.w[2][0] = w1 \n",
    "\n",
    "    num_delta4 = (loss_plus - loss_minus) / 2*epsilon\n",
    "    abs_diff4 = abs(delta4 - num_delta4)\n",
    "    \n",
    "    results.append(('hidden to output weight #2', num_delta4, delta4, abs_diff4))\n",
    "    \n",
    "    #5 input to hidden layer weight #1\n",
    "    hidden_layer = model.layers[0]\n",
    "    w1 = hidden_layer.w[2][0]\n",
    "    \n",
    "    model(x_train, y_train)\n",
    "    deltas = model.backward(False)\n",
    "    delta5 = deltas[2][0]\n",
    "    \n",
    "    hidden_layer.w[2][0] = w1 + epsilon\n",
    "    loss_plus, acc = model(x_train, y_train)\n",
    "    \n",
    "    hidden_layer.w[2][0] = w1 - epsilon\n",
    "    loss_minus, acc = model(x_train, y_train)\n",
    "    hidden_layer.w[2][0] = w1 \n",
    "\n",
    "    num_delta5 = (loss_plus - loss_minus) / 2*epsilon\n",
    "    abs_diff5 = abs(delta5 - num_delta5)\n",
    "    results.append(('input to hidden weight #1', num_delta5, delta5, abs_diff5))\n",
    "    \n",
    "    \n",
    "    #6 input to hidden layer weight #2\n",
    "    hidden_layer = model.layers[0]\n",
    "    w1 = hidden_layer.w[4][0]\n",
    "    \n",
    "    model(x_train, y_train)\n",
    "    deltas = model.backward(False)\n",
    "    delta6 = deltas[4][0]\n",
    "    \n",
    "    hidden_layer.w[4][0] = w1 + epsilon\n",
    "    loss_plus, acc = model(x_train, y_train)\n",
    "    \n",
    "    hidden_layer.w[4][0] = w1 - epsilon\n",
    "    loss_minus, acc = model(x_train, y_train)\n",
    "    hidden_layer.w[4][0] = w1 \n",
    "\n",
    "    num_delta6 = (loss_plus - loss_minus) / 2*epsilon\n",
    "    abs_diff6 = abs(delta6 - num_delta6)\n",
    "    results.append(('input to hidden weight #2', num_delta6, delta6, abs_diff6))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(0.991790 - 0.998552)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGradient(x_train,y_train,config):\n",
    "\n",
    "    subsetSize = 10  #Feel free to change this\n",
    "    sample_idx = np.random.randint(0,len(x_train),subsetSize)\n",
    "    x_train_sample, y_train_sample = x_train[sample_idx], y_train[sample_idx]\n",
    "\n",
    "    model = Neuralnetwork(config)\n",
    "    check_grad(model, x_train_sample, y_train_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
